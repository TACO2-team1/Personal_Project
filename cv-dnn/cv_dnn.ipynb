{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_data\n",
    "batch_imgs = [cv2.imread(\"two_face.jpeg\")]\n",
    "\n",
    "# init_model(ref:faceswap)\n",
    "input_size = 360\n",
    "model_filename = [\"./resnet_ssd_v1/resnet_ssd_v1.caffemodel\",\n",
    "                  \"./resnet_ssd_v1/resnet_ssd_v1.prototxt\"]\n",
    "cv2_dnn_model = cv2.dnn.readNetFromCaffe(model_filename[1], model_filename[0])\n",
    "cv2_dnn_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=cv2.dnn.blobFromImages(batch_imgs,\n",
    "                      scalefactor=1.0,\n",
    "                      size=(input_size,input_size),\n",
    "                      mean=[104, 117, 123],\n",
    "                      swapRB=False,\n",
    "                      crop=False)\n",
    "# predict\n",
    "cv2_dnn_model.setInput(input_data)\n",
    "predictions = cv2_dnn_model.forward()\n",
    "# predictions.shape -> (1,1,200,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth\n",
    "ground_truth_box=[]\n",
    "thresh_truth_confidence=0.9\n",
    "for i in range(predictions.shape[2]):\n",
    "    #批次大小，通道数（任务），输出空间个数（框的个数），每个框的属性个数\n",
    "    #属性：2-conf 3~6-rect 0,1-[0.0,1.0]??\n",
    "    confidence = predictions[0, 0, i, 2]\n",
    "    if confidence >= thresh_truth_confidence:\n",
    "        ground_truth_box.append([(predictions[0, 0, i, 3]), \n",
    "                                 (predictions[0, 0, i, 4]), \n",
    "                                 (predictions[0, 0, i, 5]), \n",
    "                                 (predictions[0, 0, i, 6])])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_box = []\n",
    "list_conf=[]\n",
    "thresh_confidence=0.01 #如果是0，log(conf)出问题\n",
    "\n",
    "for i in range(predictions.shape[2]):\n",
    "    #批次大小，通道数（任务），输出空间个数（框的个数），每个框的属性个数\n",
    "    #属性：2-conf 3~6-rect 0,1-[0.0,1.0]??\n",
    "    confidence = predictions[0, 0, i, 2]\n",
    "    if confidence >= thresh_confidence:\n",
    "        list_conf.append(predictions[0,0,i,2])\n",
    "        pred_box.append([(predictions[0, 0, i, 3]), #* input_size\n",
    "                      (predictions[0, 0, i, 4]),    #* input_size\n",
    "                      (predictions[0, 0, i, 5]),    #* input_size\n",
    "                      (predictions[0, 0, i, 6])])   #* input_size\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    # 判断是否有重叠区域\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # 没有交集\n",
    "\n",
    "    # 交集面积\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    # 并集面积\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    iou = intersection_area / union_area\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104]\n"
     ]
    }
   ],
   "source": [
    "#IOU 阈值\n",
    "thresh_IOU = 0.3\n",
    "potential_true_index = []\n",
    "potential_false_index = []\n",
    "\n",
    "for i,pred in enumerate(pred_box):    \n",
    "    math_found=False\n",
    "    for truth in ground_truth_box:\n",
    "        if calculate_iou(pred,truth)>thresh_IOU:\n",
    "            potential_true_index.append(i)\n",
    "            math_found=True\n",
    "            break\n",
    "    if not math_found:\n",
    "        potential_false_index.append(i)\n",
    "print(potential_true_index)\n",
    "print(potential_false_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(list_conf,potential_true_index,potential_false_index,threshold_false_box=1000):\n",
    "    true_detection_loss=0\n",
    "    false_detection_loss=0\n",
    "    for i in potential_true_index:\n",
    "        true_detection_loss+=np.log(1-list_conf[i])\n",
    "    #threshold_false_box 防止false_box过多\n",
    "    for j in potential_false_index[:threshold_false_box]:\n",
    "        false_detection_loss+=np.log(list_conf[j])\n",
    "    loss=true_detection_loss+false_detection_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(loss_function(list_conf,potential_true_index,potential_false_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, input_data, list_conf, potential_true_index, potential_false_index,\n",
    "               eps=0.03, alpha=0.01, attack_steps=10, device='cpu'):\n",
    "    # 将输入数据转为 PyTorch 张量，并确保可以计算梯度\n",
    "    input_data = torch.tensor(input_data, requires_grad=True, device=device)\n",
    "    input_data_orig = input_data.clone().detach()  # 原始输入的副本\n",
    "\n",
    "    for step in range(attack_steps):\n",
    "        # 前向传播并计算损失\n",
    "        model.setInput(input_data.detach().cpu().numpy())  # 将输入送入模型\n",
    "        predictions = model.forward()  # 获取模型预测\n",
    "        predictions = np.squeeze(predictions)  # 去掉冗余维度\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_function(\n",
    "            list_conf, potential_true_index, potential_false_index)\n",
    "        loss = torch.tensor(loss, requires_grad=True, device=device)\n",
    "\n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 梯度上升更新（针对 untargeted attack）\n",
    "        grad = input_data.grad.data\n",
    "        input_data = input_data + alpha * grad.sign()\n",
    "\n",
    "        # 投影步骤，将输入限制在 (input_data_orig - eps) 到 (input_data_orig + eps) 范围内\n",
    "        input_data = torch.clamp(\n",
    "            input_data, input_data_orig - eps, input_data_orig + eps)\n",
    "\n",
    "        # 重新约束输入到合法范围 (0, 255) 范围\n",
    "        input_data = torch.clamp(input_data, 0, 255)\n",
    "\n",
    "        # 清空梯度，以便下一步计算\n",
    "        input_data.grad.zero_()\n",
    "\n",
    "    # 返回对抗样本\n",
    "    return input_data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Net 0000018B3D9CBCB0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2_dnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpgd_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2_dnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpotential_true_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpotential_false_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m, in \u001b[0;36mpgd_attack\u001b[1;34m(model, input_data, list_conf, potential_true_index, potential_false_index, eps, alpha, attack_steps, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 梯度上升更新（针对 untargeted attack）\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[0;32m     23\u001b[0m input_data \u001b[38;5;241m=\u001b[39m input_data \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m grad\u001b[38;5;241m.\u001b[39msign()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 投影步骤，将输入限制在 (input_data_orig - eps) 到 (input_data_orig + eps) 范围内\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "pgd_attack(cv2_dnn_model,input_data,list_conf,potential_true_index,potential_false_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在原图画pred_box\n",
    "for img in batch_imgs:\n",
    "    for (x1,y1,x2,y2) in pred_box:\n",
    "        height,width,_=img.shape\n",
    "        x1, y1, x2, y2 = int(x1*width), int(y1*height), int(x2*width), int(y2*height)\n",
    "        color = (0, 255, 0)\n",
    "        thickness = 2  \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "    # 显示图像\n",
    "    cv2.imshow(\"Image with Faces\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceswap",
   "language": "python",
   "name": "faceswap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
